{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport keras\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras import regularizers\nfrom sklearn.model_selection import train_test_split\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"b65da47eb3f1b916b1a5ebb686a9f161637eb44c"},"cell_type":"code","source":"train_dir = '../input/asl_alphabet_train/asl_alphabet_train'\ntest_dir = '../input/asl_alphabet_test/asl_alphabet_test'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4602132ec7e66a9f42a69ec337cd47ce1aeea06e"},"cell_type":"code","source":"def load_unique():\n    size_img = 64,64 \n    images_for_plot = []\n    labels_for_plot = []\n    for folder in os.listdir(train_dir):\n        for file in os.listdir(train_dir + '/' + folder):\n            filepath = train_dir + '/' + folder + '/' + file\n            image = cv2.imread(filepath)\n            final_img = cv2.resize(image, size_img)\n            final_img = cv2.cvtColor(final_img, cv2.COLOR_BGR2RGB)\n            images_for_plot.append(final_img)\n            labels_for_plot.append(folder)\n            break\n    return images_for_plot, labels_for_plot\n\nimages_for_plot, labels_for_plot = load_unique()\nprint(\"unique_labels = \", labels_for_plot)\n\nfig = plt.figure(figsize = (15,15))\ndef plot_images(fig, image, label, row, col, index):\n    fig.add_subplot(row, col, index)\n    plt.axis('off')\n    plt.imshow(image)\n    plt.title(label)\n    return\n\nimage_index = 0\nrow = 5\ncol = 6\nfor i in range(1,(row*col)):\n    plot_images(fig, images_for_plot[image_index], labels_for_plot[image_index], row, col, i)\n    image_index = image_index + 1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e76c9debca042ed40548e5e7ddf40f0b63481732"},"cell_type":"code","source":"labels_dict = {'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,\n                   'N':13,'O':14,'P':15,'Q':16,'R':17,'S':18,'T':19,'U':20,'V':21,'W':22,'X':23,'Y':24,\n                   'Z':25,'space':26,'del':27,'nothing':28}\n\nimages = []\nlabels = []\nsize = 64,64\n\nfor folder in os.listdir(train_dir):\n    print(folder, end = ' | ')\n    for image in os.listdir(train_dir + \"/\" + folder):\n        temp_img = cv2.imread(train_dir + '/' + folder + '/' + image)\n        temp_img = cv2.resize(temp_img, size)\n        images.append(temp_img)\n        labels.append(labels_dict[folder])\n\nimages = np.array(images)\nimages = images.astype('float32') / 255.0\n\nlabels = keras.utils.to_categorical(labels)\n\nX_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size = 0.05)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88ecd06584207f8caa65d810e6ed695edd1ed90e"},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(16, kernel_size = [3,3], padding = 'same', activation = 'relu', input_shape = (64,64,3)))\nmodel.add(Conv2D(32, kernel_size = [3,3], padding = 'same', activation = 'relu'))\n#model.add(Dropout(0.3))\nmodel.add(MaxPool2D(pool_size = [3,3]))\n\nmodel.add(Conv2D(32, kernel_size = [3,3], padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(64, kernel_size = [3,3], padding = 'same', activation = 'relu'))\n#model.add(Dropout(0.3))\nmodel.add(MaxPool2D(pool_size = [3,3]))\n\nmodel.add(Conv2D(128, kernel_size = [3,3], padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(256, kernel_size = [3,3], padding = 'same', activation = 'relu'))\n#model.add(Dropout(0.3))\nmodel.add(MaxPool2D(pool_size = [3,3]))\n\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(512, activation = 'relu', kernel_regularizer = regularizers.l2(0.001)))\nmodel.add(Dense(29, activation = 'softmax'))\n\nmodel.compile(optimizer = 'adam', loss = keras.losses.categorical_crossentropy, metrics = [\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"HISTORY = model.fit(X_train, Y_train, batch_size = 64, epochs = 5, validation_split = 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad0ae00b99bd641fc4b1ac931cdcb1a1ca3d4902"},"cell_type":"code","source":"plt.plot(HISTORY.history['acc'])\nplt.plot(HISTORY.history['val_acc'])\nplt.legend(['train', 'test'], loc='lower right')\nplt.title('accuracy plot - train vs test')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(HISTORY.history['loss'])\nplt.plot(HISTORY.history['val_loss'])\nplt.legend(['training loss', 'validation loss'], loc = 'upper right')\nplt.title('loss plot - training vs vaidation')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1a7865fbd596b1bc5b5dab31e4b5041a28af25b"},"cell_type":"code","source":"evaluate_metrics = model.evaluate(X_test, Y_test)\nprint(\"\\nEvaluation Accuracy = \", \"{:.2f}%\".format(evaluate_metrics[1]*100),\"\\nEvaluation loss = \" ,\"{:.6f}\".format(evaluate_metrics[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('sign_model.h5')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}